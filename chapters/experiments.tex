% !TEX root = ../main.tex

\chapter{Experiments} % (fold)
\label{cha:Experiments}

\section{DeepWalk}

Deepwalk is an algorithm to learn latent representation in a network.
It is the first of its kind to take successful techniques usually reserved for natural language processing and apply them to network analysis.

To learn the features and relations between vertices, the algorithm walks randomly through a network.
Deepwalk is a form of unsupervised learning: the model learns independently from the labels, if available.
This makes it a powerful algorithm for finding latents representation in very large networks even with sparse data.

Deepwalk is based primarily on the SkipGram model, often referred to as \textit{word2vec}. 
\textit{Word2vec} is a technique created for natural language processing published in 2013.
It is used to perform word embeddings: in a higher dimensional space, words of similar meaning and used in similar context are grouped together, away from the words used in a different context.
Here, Deepwalk applies this technique to learn the relationship between nodes in a network.
The idea behind it is to treat a network as a document.
Since we're working with network, the SkipGram model is trained with each random walk performed.
In natural language processing, \textit{word2vec} represents words with similar meaning close to another in the resulting embedding space; in Deepwalk, this will be the case for nodes with similar features.

Deepwalk has four main hyperparameters which can be tuned to obtain a better representation of the network.
We can choose the size of the context of a SkipGram model: in NLP, this is the number of words included before and a after a word to then chose the next one.
With a network, this will be the number of neighboring vertices to take into account for the next random walk.

In addition, the output embedding can be tuned via the embedding size \textit{d}.
This is the number of latent dimensions we want to have for a graph.
A higher or lower dimensionality can result in a better representation of the network in the embedding space.
However more dimensions does not necessarily mean better results.
It is important to find the right hyperparameter which leads to the best results.

We can set the number of random walk started at each vertex with the parameter \textit{\gamma}, and the length of each random walk with the parameter \textit{t}.
Through these parameters, we can tune DeepWalk's random walk behaviour. 
Depending on the network, we might prefer DeepWalk to do numerous short walk or few long ones.

\subsection{DeepWalk With Disinformation Dataset and Parameters Sensitivity}

We used DeepWalk algorithm on our disinformation dataset.
For this experiment we perform the graph embedding on the adjacency list discussed in subsection~\ref{sub:h2h}.
In a text, more context helps the algorithm to better understand the meaning of a word and how to place them in the embedding space.
Similarly, more vertices helps gain information on the network underlying function.
For this reason, we use the entire network data to perform the embedding.

The resulting embedding representation is then cleaned from users and sources entities so that we score only the news articles.
To transform the network to homogeneous, we assigned a unique index for each entity and mapped it to the graph's edge list.
Conveniently, we can reuse this mapping to now remove all indexes which are not news entities.

\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \scalebox{.5}{\input{figures/plots/deepwalk/deepwalk-plot-dimensions-window-size.pgf}}
        \label{fig:deepwalk:representation window size}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \scalebox{.5}{\input{figures/plots/deepwalk/deepwalk-plot-number-length-walk.pgf}}
        \label{fig:deepwalk:number walk length}
    \end{subfigure}
    \caption{DeepWalk results.}
    \label{fig:deepwalk:plots}
\end{figure}

A new classification model is trained on the cleaned embedding to classify fake and real news.
We use the news labels provided with the dataset as targets.
Ideally news should be grouped together by veracity in the resulting embedding space since they share similar characteristics.
Here, we want to test if DeepWalk was able to group them well.

To obtain the best performance, each hyperparameter of the algorithm is tuned one after the other.
We first tune the number of dimensions \textit{d}, with all the other parameters set to their respective default.
We select the number of dimensions which resulted in the best F-score.
This value is then used for all remaining parameters tuning.
This process is repeated for the \textit{w}, \textit{\gamma} and \textit{t} parameters in this order.
We always use the best parameter value for the parameters previously tuned, and leave the other left to tune to their default values.

Figure~\ref{fig:deepwalk:plots} showcases the F-score obtained for all 4 parameters tuning.

For DeepWalk, the best parameters are $d=64, w=10, \gamma=20, t=40$.
For the misinformation network, DeepWalks prefer few but quite short random walks with an average number of vertices to chose from.

\newpage
\section{Node2vec}

The node2vec algorithm uses a similar embedding approach as DeepWalk: random walks through the network to learn latent features.

However node2vec's authors found that purely random walk sometimes did not give the best possible result.
Indeed if the walks are purely random, we could obtain very different embeddings between two instances of DeepWalk on the same network.
For this reason, they decided to add two additional hyperparameters: tuning for breadth first search and depth first search.
These two concepts can be tuned through the return parameter denoted \textit{p} and in-out parameter denoted \textit{q}.
These two parameters are probability and influences the exploration of the network.
They are used as $1/p$ and $1/p$ by the algorithm in the graph.

The return parameter controls how often the algorithm revisits a node previously visited in the network.
Thanks to this parameter, we can tune the random walks behaviour.
A high value for this parameter makes it less likely we revisit a node and encourages exploration.
While A low value ensure the algorithm walks closely to the starting node.

The in-out parameter controls the probability to visit not yet visited neighbours. A high value will encourage exploration away from the neighborhood while a low value will lead to a more conservative walk on the graph. 

\subsection{Node2vec with Disinformation Dataset and Parameters Sensitivity}

Just like for Deepwalk, we again perform the embedding with node2vec on the integrity of the network to gain from the additional context provided by users and news source.
We always clean the resulting embedding, since we want to perform the classification on the news entity only.

Before tuning the four hyperparameters for the output embedding, we must first tune the \textit{p} and \textit{q} parameters.
We obtained embeddings by iterating over these two parameters with a set of 5 values for each, for a total of 25 runs. All other parameters are set to their default.
Table~\ref{tab:node2vec:pqMicro} shows us the micro F1 score obtained by tuning these parameters.
We obtain $p=2$ and $q=1$ as the best parameters for the node2vec with the fake news dataset.
\begin{table}[h]
    \centering
    \caption{Micro F1 score for $p$ and $q$.}
    \label{tab:node2vec:pqMicro}
    \begin{tabular}{llllll}
        \diagbox[height=0.8cm]{p}{q} & 0.25 & 0.5 & 1.0 & 2.0 & 4.0 \\
        0.25 & 0.6564 & 0.6720 & 0.6550 & 0.6583 & 0.6564 \\
        0.5 & 0.6493 & 0.6635 & 0.6687 & 0.6408 & 0.6450 \\
        1.0 & 0.6649 & 0.6848 & 0.6536 & 0.6640 & 0.6588 \\
        2.0 & 0.6829 & 0.6716 & \bfseries 0.6943 & 0.6744 & 0.6654 \\
        4.0 & 0.6749 & 0.6739 & 0.6773 & 0.6540 & 0.6815 \\
    \end{tabular}
\end{table}

Just like for DeepWalk, when then tune each four hyperparameters so we can obtain the best possible results for this algorithm on our dataset.
We first tune the number of dimensions and leave all other parameters left to tune to their default. 
We pick the parameter value for the number of dimensions which gave the best F1 score and use this value for all next runs. 
The parameters which gave the best F1 score for each run is picked for the tuning of the following parameters.
We continue doing this for the window size, the random walk length and the number of random walk. 

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \scalebox{.5}{\input{figures/plots/node2vec/node2vec-plot-dimensions-window-size.pgf}}
        \label{fig:node2vec:representation and window size}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \scalebox{.5}{\input{figures/plots/node2vec/node2vec-plot-number-length-walk.pgf}}
        \label{fig:node2vec:number and walk length}
    \end{subfigure}
    \caption{Node2vec results.}
    \label{fig:deepwalk:plots}
\end{figure}

\section{DeepWalk and Node2vec Results Discussion}
The parameters which resulted in the best score for node2vec on our disinformation dataset are $p=2, q=1, d=128, w=1, \gamma=60,t=20 $.

for node2vec, the best window size parameter was 1, compared with 10 for DeepWalk.
This means that node2vec consider only one possible node for the next step of the random walk.
We believe this strong difference in window size between the two algorithm could be due to the additional p and q hyperparameters of node2vec.
With a value of $p=2, q=1$, node2vec prioritize exploration over revisiting known nodes.
Because our graph is highly connected, network exploration means fewer but longer random walk, as we can see from $\gamma=60$ and $t=20$ for node2vec.
The hyperparameters $\gamma=20$ and $t=40$ shows that DeepWalk prioritize network exploration through randomness, with shorter but more numerous walks.

Compared with DeepWalk, we can a see slightly better performance improved by node2vec.
DeepWalk strictly performs the network exploration randomly. 
Node2vec has a small edge here, because its walks can be influenced through $p$ and $q$ parameters.
In a large network such as the misinformation dataset we use here, this improves the graph exploration slightly.
In our best result, we prioritize exploration of unknown nodes on the network over already visited ones.
This leads to a slight but significant improvement in the algorithm's network knowledge and thus a better representation in the resulting embeddings. 

\newpage
\section{Score Comparsion}

With our two algorithms best performance, we can now compare their performance compared to FANG.
In FANG's original paper, its performance was measured with Area Under the ROC Curve, AUC for short.
Conveniently FANG also produces a F1 score when we perform it on our dataset.
We will therefore use both metrics to compare the performance of these algorithms.

We measured the performance of Deepwalk and node2vec on an embedding performed with the best parameters, discussed previsouly in chapter~\ref{cha:Experiments}.
For FANG, we enabled all hyperparameters such that it uses all available context, therefore obtain the best performance possible.

\begin{table}[h]
    \centering
    \caption{Comparison between models, evaluated with F1 score and AUC.}
    \label{tab:f1_auc}
    \begin{tabular}{lcc}
        \toprule
        Model & F1 score (micro) & AUC \\
        \midrule
        % TODO update these values with BINARY F1, not micro!
        DeepWalk & 0.6810 & 0.6493 \\
        node2vec & 0.6844 & 0.6654 \\
        % these are the final values at 80%
        FANG & 0.6268 & 0.6701 \\
        \bottomrule
    \end{tabular}
\end{table}
We can now compare these metrics of both algorithm with the one from Factual News Graph (FANG).

\iffalse
\subsubsection{Notes}

Just like Deepwalk and node2vec, FANG produces both F1 score and AUC using the sklearn library.
The AUC uses the default ($average=macro$).

However the F1 produced uses $average=binary$.
We have F1 micro and macro score for DeepWalk and node2vec.
Which one should we use, or do we need to run the program with binary F1?

%%%%% RAW SCORE %%%%%
% DEEPWALk
% F1 score Average score: {'micro': 0.6810426540284359, 'macro': 0.6675884947364201}
% AUC Average score: {'micro': 0.6668246445497629, 'macro': 0.6492556721962208}

% NODE2VEC
% F1 score Average score: {'micro': 0.6843601895734597, 'macro': 0.6642412717978502}
% AUC Average score: {'micro': 0.6909952606635071, 'macro': 0.6654164938979849}
%%%%% RAW SCORE %%%%%

% 80% of the data would mean 843 news article to train on
\fi
